{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsWx93yJsb-i",
        "outputId": "17844cf5-511f-4842-a351-df3bff0e3254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 9600 files belonging to 4 classes.\n",
            "Found 1200 files belonging to 4 classes.\n",
            "Found 1200 files belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score , confusion_matrix\n",
        "\n",
        "import itertools\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify the path to your folder\n",
        "folder_path = '/content/drive/My Drive/Final Training Data'\n",
        "dataPath= os.path.join(os.getcwd(), 'drive', 'My Drive', 'Final Training Data')\n",
        "# Define the base directory where your class folders are located\n",
        "base_dir = dataPath\n",
        "\n",
        "# Define the destination base directories\n",
        "train_dir = os.path.join(dataPath, \"Train\")\n",
        "test_dir = os.path.join(dataPath, \"Test\")\n",
        "valid_dir = os.path.join(dataPath, \"Valid\")\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_HEIGHT = 256\n",
        "IMAGE_WIDTH = 256\n",
        "train_dataset = keras.utils.image_dataset_from_directory(\n",
        "    os.path.join(dataPath, 'Train'),\n",
        "    image_size = (IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "\n",
        "valid_dataset = keras.utils.image_dataset_from_directory(\n",
        "    os.path.join(dataPath, 'Valid'),\n",
        "    image_size = (IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "\n",
        "test_dataset = keras.utils.image_dataset_from_directory(\n",
        "    os.path.join(dataPath, 'Test'),\n",
        "    image_size = (IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    label_mode = 'categorical',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "data_augmentation = keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal\"), # Applies horizontal flipping to a random 50% of the images\n",
        "  layers.RandomRotation(0.1), # Rotates the input images by a random value in the range[–10%, +10%] (fraction of full circle [-36°, 36°])\n",
        "  layers.RandomZoom(0.1), # Zooms in or out of the image by a random factor in the range [-20%, +20%]\n",
        "  layers.RandomContrast(0.1),\n",
        "],\n",
        "name = \"AugmentationLayer\"\n",
        ")\n",
        "\n",
        "model = keras.Sequential(name=\"FromScratch\")\n",
        "model.add(data_augmentation)\n",
        "model.add(layers.Rescaling(1./255))\n",
        "\n",
        "model.add(layers.Conv2D(32, kernel_size = 3, activation = \"relu6\", padding = \"same\", input_shape = (256, 256,3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(64, kernel_size = 3, activation='relu', padding = \"same\"))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(128, kernel_size = 3, activation='relu', padding = \"same\"))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(256, kernel_size = 3, activation='relu', padding = \"same\"))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(512, kernel_size = 3, activation='relu', padding = \"same\"))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(512, kernel_size = 3, activation='relu', padding = \"same\"))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "model.add(layers.Dense(256,activation=\"relu\"))\n",
        "model.add(layers.Dense(4,activation=\"softmax\"))\n",
        "\n",
        "model.build(input_shape=(None, 256, 256, 3))\n",
        "model.add(Flatten())\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxbF-5DHuvva",
        "outputId": "1e4bfa9f-fd0c-4b9f-df1f-845da9c580b6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"FromScratch\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " AugmentationLayer (Sequent  (None, 256, 256, 3)       0         \n",
            " ial)                                                            \n",
            "                                                                 \n",
            " rescaling (Rescaling)       (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 256, 256, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 128, 128, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 128, 128, 32)      128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 128, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 64, 64, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 64, 64, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 64, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 32, 32, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 32, 32, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 256)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 16, 16, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 16, 16, 512)       1180160   \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 8, 8, 512)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 8, 8, 512)         2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 4, 4, 512)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 4, 4, 512)         2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               2097408   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 1028      \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 4)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6032836 (23.01 MB)\n",
            "Trainable params: 6029828 (23.00 MB)\n",
            "Non-trainable params: 3008 (11.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "# Convert the model.\n",
        "modelName = \"fin\"\n",
        "scratchPath=scratchPath = os.path.join(dataPath, 'models', 'from_scratch')\n",
        "modelPath = os.path.join(scratchPath, modelName + \".keras\")\n",
        "model=tf.keras.models.load_model(modelPath, compile=False)\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "files.download('model.tflite')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "S-8skerWsfr4",
        "outputId": "4a28063d-3cfe-4453-cb2a-8e75976edca2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_87a39e3b-ca83-4fde-8ad7-ebcf30ce6185\", \"model.tflite\", 24129488)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}